{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f47f59f-6677-48e1-86f6-8b725c3263f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as smf\n",
    "import torch\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "import torchtuples as tt\n",
    "from torchtuples import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn, Tensor\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "import os\n",
    "os.environ[\"R_HOME\"] = f\"{os.environ['CONDA_PREFIX']}\\\\Lib\\\\R\"\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects.packages import importr\n",
    "importr('quantreg')\n",
    "\n",
    "from pytorchtools import EarlyStopping\n",
    "import torch.utils.data as Data\t# For constructing DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch import nn, Tensor\n",
    "from dqAux_new import dqNetSparse,checkLoss\n",
    "from localrqgrid import lprq0g\n",
    "from localrq import lprq0\n",
    "from ph import ph\n",
    "from bandwidthaic import bandwidthaic\n",
    "from ci import cifint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08a8c2cb-7bdf-46ae-89ca-330fafb67abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define functional coefficients\n",
    "def g10(x): return 1.5*np.exp(-3*(x+1)**2)+1*np.exp(-8*(x-1)**2)\n",
    "def g11(x): return (0.15*np.exp(4*x)/(1+np.exp(4*x)))\n",
    "def g12(x): return (0.04*(x)**2)\n",
    "def g13(x): return (0.15*np.exp(-4*x)/(1+np.exp(-4*x)))\n",
    "def g14(x): return (0.1*((np.cos(x))**2))\n",
    "def g15(x): return (0.15*np.exp(4*x)/(1+np.exp(4*x)))\n",
    "def g16(x): return (0.04*(x)**2)\n",
    "def g17(x): return (0.15*np.exp(-4*x)/(1+np.exp(-4*x)))\n",
    "def g18(x): return (0.1*((np.cos(x))**2))\n",
    "\n",
    "def g20(x): return 1.5*np.exp(-3*(x-1)**2)+1*np.exp(-8*(x+1)**2)\n",
    "def g21(x): return (0.1*np.sin(-0.8*np.pi*x)+0.1)\n",
    "def g22(x): return (0.15*np.exp(4*x)/(1+np.exp(4*x)))\n",
    "def g23(x): return (0.1*np.sin(-0.8*np.pi*x)+0.1)\n",
    "def g24(x): return (0.15*np.exp(-4*x)/(1+np.exp(-4*x)))\n",
    "def g25(x): return (0.1*np.sin(-0.8*np.pi*x)+0.1)\n",
    "def g26(x): return (0.15*np.exp(4*x)/(1+np.exp(4*x)))\n",
    "def g27(x): return (0.1*np.sin(-0.8*np.pi*x)+0.1)\n",
    "def g28(x): return (0.15*np.exp(-4*x)/(1+np.exp(-4*x)))\n",
    "\n",
    "def g30(x): return 1.5*np.exp(-3*(x+1)**2)+1*np.exp(-8*(x-1)**2)\n",
    "def g31(x): return (0.1*np.sin(0.8*np.pi*x)+0.1)\n",
    "def g32(x): return (0.1*np.cos(0.8*np.pi*x)+0.1)\n",
    "def g33(x): return (0.1*np.sin(0.8*np.pi*x)+0.1)\n",
    "def g34(x): return (0.1*np.cos(0.8*np.pi*x)+0.1)\n",
    "def g35(x): return (0.1*np.sin(0.8*np.pi*x)+0.1)\n",
    "def g36(x): return (0.1*np.cos(0.8*np.pi*x)+0.1)\n",
    "def g37(x): return (0.1*np.sin(0.8*np.pi*x)+0.1)\n",
    "def g38(x): return (0.1*np.cos(0.8*np.pi*x)+0.1)\n",
    "\n",
    "def g40(x): return 1.5*np.exp(-3*(x-1)**2)+1*np.exp(-8*(x+1)**2)\n",
    "def g41(x): return (0.1*np.cos(0.8*np.pi*x)+0.1)\n",
    "def g42(x): return (0.1*np.sin(0.8*np.pi*x)+0.1)\n",
    "def g43(x): return (0.1*np.cos(0.8*np.pi*x)+0.1)\n",
    "def g44(x): return (0.1*np.sin(0.8*np.pi*x)+0.1)\n",
    "def g45(x): return (0.1*np.cos(0.8*np.pi*x)+0.1)\n",
    "def g46(x): return (0.1*np.sin(0.8*np.pi*x)+0.1)\n",
    "def g47(x): return (0.1*np.cos(0.8*np.pi*x)+0.1)\n",
    "def g48(x): return (0.1*np.sin(0.8*np.pi*x)+0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a38cc045-33da-4c53-b92e-0d4e6d22705f",
   "metadata": {},
   "outputs": [],
   "source": [
    " tau=0.15\n",
    " n=4000\n",
    " nt=4000\n",
    " nv=800\n",
    "\n",
    " #testing data\n",
    " index=np.zeros((n,1))\n",
    " coefx1=np.zeros((n,9))\n",
    " coefx2=np.zeros((n,9))\n",
    " coefx3=np.zeros((n,9))\n",
    " coefx4=np.zeros((n,9))\n",
    "  \n",
    " Y1=np.zeros((n,1))\n",
    " Y1[0]=0\n",
    " stdev1=np.zeros((n,1))\n",
    " stdev1[0]=1\n",
    " Y2=np.zeros((n,1))\n",
    " Y2[0]=0\n",
    " stdev2=np.zeros((n,1))\n",
    " stdev2[0]=1\n",
    "  \n",
    " Y3=np.zeros((n,1))\n",
    " Y3[0]=0\n",
    " stdev3=np.zeros((n,1))\n",
    " stdev3[0]=1\n",
    " Y4=np.zeros((n,1))\n",
    " Y4[0]=0\n",
    " stdev4=np.zeros((n,1))\n",
    " stdev4[0]=1\n",
    "\n",
    " #training data\n",
    " indext=np.zeros((nt,1))\n",
    " coefx1t=np.zeros((nt,9))\n",
    " coefx2t=np.zeros((nt,9))\n",
    " coefx3t=np.zeros((nt,9))\n",
    " coefx4t=np.zeros((nt,9))\n",
    "  \n",
    " Y1t=np.zeros((nt,1))\n",
    " Y1t[0]=0\n",
    " stdev1t=np.zeros((nt,1))\n",
    " stdev1t[0]=1\n",
    " Y2t=np.zeros((nt,1))\n",
    " Y2t[0]=0\n",
    " stdev2t=np.zeros((nt,1))\n",
    " stdev2t[0]=1\n",
    "  \n",
    " Y3t=np.zeros((nt,1))\n",
    " Y3t[0]=0\n",
    " stdev3t=np.zeros((nt,1))\n",
    " stdev3t[0]=1\n",
    " Y4t=np.zeros((nt,1))\n",
    " Y4t[0]=0\n",
    " stdev4t=np.zeros((nt,1))\n",
    " stdev4t[0]=1\n",
    "\n",
    " #validation data\n",
    " indexv=np.zeros((nv,1))\n",
    " coefx1v=np.zeros((nv,9))\n",
    " coefx2v=np.zeros((nv,9))\n",
    " coefx3v=np.zeros((nv,9))\n",
    " coefx4v=np.zeros((nv,9))\n",
    "  \n",
    " Y1v=np.zeros((nv,1))\n",
    " Y1v[0]=0\n",
    " stdev1v=np.zeros((nv,1))\n",
    " stdev1v[0]=1\n",
    " Y2v=np.zeros((nv,1))\n",
    " Y2v[0]=0\n",
    " stdev2v=np.zeros((nv,1))\n",
    " stdev2v[0]=1\n",
    "  \n",
    " Y3v=np.zeros((nv,1))\n",
    " Y3v[0]=0\n",
    " stdev3v=np.zeros((nv,1))\n",
    " stdev3v[0]=1\n",
    " Y4v=np.zeros((nv,1))\n",
    " Y4v[0]=0\n",
    " stdev4v=np.zeros((nv,1))\n",
    " stdev4v[0]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96521096-0620-4b4a-82f8-fac91edd6915",
   "metadata": {},
   "outputs": [],
   "source": [
    " #testing data\n",
    " for j in range(2,(n+1)):\n",
    "    \n",
    "     index[j-1]=np.random.uniform(-2,2+10**-10,1)\n",
    "     e1=np.random.uniform(0,1+10**-10,1)\n",
    "     e2=np.random.uniform(0,1+10**-10,1)\n",
    "     e3=np.random.uniform(0,1+10**-10,1)\n",
    "     e4=np.random.uniform(0,1+10**-10,1)\n",
    "     e31=(0.2*(e1)**2)+0.8\n",
    "     e32=(0.2*np.exp(e1))+0.8\n",
    "     e41=(0.2*(e2)**2)+0.8\n",
    "     e42=(0.2*np.exp(e2))+0.8\n",
    "     e51=(0.2*(e3)**2)+0.8\n",
    "     e52=(0.2*np.exp(e3))+0.8\n",
    "     e61=(0.2*(e4)**2)+0.8\n",
    "     e62=(0.2*np.exp(e4))+0.8\n",
    "    \n",
    "     e5=np.random.normal(0,1,1)\n",
    "     e6=np.random.normal(0,1,1)   \n",
    "     e7=np.random.normal(0,1,1) \n",
    "     e8=np.random.normal(0,1,1) \n",
    "\n",
    "     coefx1[j-1,]=[g10(index[j-1]).item(),(g11(index[j-1])*e31).item(),(g12(index[j-1])*e32).item(),(g13(index[j-1])*e31).item(),(g14(index[j-1])*e32).item(),g15(index[j-1]).item(),g16(index[j-1]).item(),g17(index[j-1]).item(),g18(index[j-1]).item()]\n",
    "     coefx2[j-1,]=[g20(index[j-1]).item(),(g21(index[j-1])*e41).item(),(g22(index[j-1])*e42).item(),(g23(index[j-1])*e41).item(),(g24(index[j-1])*e42).item(),g25(index[j-1]).item(),g26(index[j-1]).item(),g27(index[j-1]).item(),g28(index[j-1]).item()]\n",
    "     coefx3[j-1,]=[g30(index[j-1]).item(),(g31(index[j-1])*e51).item(),(g32(index[j-1])*e52).item(),(g33(index[j-1])*e51).item(),(g34(index[j-1])*e52).item(),g35(index[j-1]).item(),g36(index[j-1]).item(),g37(index[j-1]).item(),g38(index[j-1]).item()]\n",
    "     coefx4[j-1,]=[g40(index[j-1]).item(),(g41(index[j-1])*e61).item(),(g42(index[j-1])*e62).item(),(g43(index[j-1])*e61).item(),(g44(index[j-1])*e62).item(),g45(index[j-1]).item(),g46(index[j-1]).item(),g47(index[j-1]).item(),g48(index[j-1]).item()]\n",
    "    \n",
    "     stdev1[j-1]=np.dot(coefx1[j-1,],[1,stdev1[j-2].item(),stdev2[j-2].item(),stdev3[j-2].item(),stdev4[j-2].item(),np.absolute(Y1[j-2]).item(),np.absolute(Y2[j-2]).item(),np.absolute(Y3[j-2]).item(),np.absolute(Y4[j-2]).item()])\n",
    "     stdev2[j-1]=np.dot(coefx2[j-1,],[1,stdev1[j-2].item(),stdev2[j-2].item(),stdev3[j-2].item(),stdev4[j-2].item(),np.absolute(Y1[j-2]).item(),np.absolute(Y2[j-2]).item(),np.absolute(Y3[j-2]).item(),np.absolute(Y4[j-2]).item()])\n",
    "     stdev3[j-1]=np.dot(coefx3[j-1,],[1,stdev1[j-2].item(),stdev2[j-2].item(),stdev3[j-2].item(),stdev4[j-2].item(),np.absolute(Y1[j-2]).item(),np.absolute(Y2[j-2]).item(),np.absolute(Y3[j-2]).item(),np.absolute(Y4[j-2]).item()])\n",
    "     stdev4[j-1]=np.dot(coefx4[j-1,],[1,stdev1[j-2].item(),stdev2[j-2].item(),stdev3[j-2].item(),stdev4[j-2].item(),np.absolute(Y1[j-2]).item(),np.absolute(Y2[j-2]).item(),np.absolute(Y3[j-2]).item(),np.absolute(Y4[j-2]).item()])\n",
    "    \n",
    "     Y1[j-1]=stdev1[j-1]*e5\n",
    "     Y2[j-1]=stdev2[j-1]*e6\n",
    "     Y3[j-1]=stdev3[j-1]*e7\n",
    "     Y4[j-1]=stdev4[j-1]*e8\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "664e02c7-d3ab-4953-9373-2cc7c7fcb7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    " #training data\n",
    " for j in range(2,(nt+1)):\n",
    "    \n",
    "     indext[j-1]=np.random.uniform(-2,2+10**-10,1)\n",
    "     e1t=np.random.uniform(0,1+10**-10,1)\n",
    "     e2t=np.random.uniform(0,1+10**-10,1)\n",
    "     e3t=np.random.uniform(0,1+10**-10,1)\n",
    "     e4t=np.random.uniform(0,1+10**-10,1)\n",
    "     e31t=(0.2*(e1t)**2)+0.8\n",
    "     e32t=(0.2*np.exp(e1t))+0.8\n",
    "     e41t=(0.2*(e2t)**2)+0.8\n",
    "     e42t=(0.2*np.exp(e2t))+0.8\n",
    "     e51t=(0.2*(e3t)**2)+0.8\n",
    "     e52t=(0.2*np.exp(e3t))+0.8\n",
    "     e61t=(0.2*(e4t)**2)+0.8\n",
    "     e62t=(0.2*np.exp(e4t))+0.8\n",
    "\n",
    "     e5t=np.random.normal(0,1,1)\n",
    "     e6t=np.random.normal(0,1,1)   \n",
    "     e7t=np.random.normal(0,1,1) \n",
    "     e8t=np.random.normal(0,1,1) \n",
    "\n",
    "     coefx1t[j-1,]=[g10(indext[j-1]).item(),(g11(indext[j-1])*e31t).item(),(g12(indext[j-1])*e32t).item(),(g13(indext[j-1])*e31t).item(),(g14(indext[j-1])*e32t).item(),g15(indext[j-1]).item(),g16(indext[j-1]).item(),g17(indext[j-1]).item(),g18(indext[j-1]).item()]\n",
    "     coefx2t[j-1,]=[g20(indext[j-1]).item(),(g21(indext[j-1])*e41t).item(),(g22(indext[j-1])*e42t).item(),(g23(indext[j-1])*e41t).item(),(g24(indext[j-1])*e42t).item(),g25(indext[j-1]).item(),g26(indext[j-1]).item(),g27(indext[j-1]).item(),g28(indext[j-1]).item()]\n",
    "     coefx3t[j-1,]=[g30(indext[j-1]).item(),(g31(indext[j-1])*e51t).item(),(g32(indext[j-1])*e52t).item(),(g33(indext[j-1])*e51t).item(),(g34(indext[j-1])*e52t).item(),g35(indext[j-1]).item(),g36(indext[j-1]).item(),g37(indext[j-1]).item(),g38(indext[j-1]).item()]\n",
    "     coefx4t[j-1,]=[g40(indext[j-1]).item(),(g41(indext[j-1])*e61t).item(),(g42(indext[j-1])*e62t).item(),(g43(indext[j-1])*e61t).item(),(g44(indext[j-1])*e62t).item(),g45(indext[j-1]).item(),g46(indext[j-1]).item(),g47(indext[j-1]).item(),g48(indext[j-1]).item()]\n",
    "    \n",
    "     stdev1t[j-1]=np.dot(coefx1t[j-1,],[1,stdev1t[j-2].item(),stdev2t[j-2].item(),stdev3t[j-2].item(),stdev4t[j-2].item(),np.absolute(Y1t[j-2]).item(),np.absolute(Y2t[j-2]).item(),np.absolute(Y3t[j-2]).item(),np.absolute(Y4t[j-2]).item()])\n",
    "     stdev2t[j-1]=np.dot(coefx2t[j-1,],[1,stdev1t[j-2].item(),stdev2t[j-2].item(),stdev3t[j-2].item(),stdev4t[j-2].item(),np.absolute(Y1t[j-2]).item(),np.absolute(Y2t[j-2]).item(),np.absolute(Y3t[j-2]).item(),np.absolute(Y4t[j-2]).item()])\n",
    "     stdev3t[j-1]=np.dot(coefx3t[j-1,],[1,stdev1t[j-2].item(),stdev2t[j-2].item(),stdev3t[j-2].item(),stdev4t[j-2].item(),np.absolute(Y1t[j-2]).item(),np.absolute(Y2t[j-2]).item(),np.absolute(Y3t[j-2]).item(),np.absolute(Y4t[j-2]).item()])\n",
    "     stdev4t[j-1]=np.dot(coefx4t[j-1,],[1,stdev1t[j-2].item(),stdev2t[j-2].item(),stdev3t[j-2].item(),stdev4t[j-2].item(),np.absolute(Y1t[j-2]).item(),np.absolute(Y2t[j-2]).item(),np.absolute(Y3t[j-2]).item(),np.absolute(Y4t[j-2]).item()])\n",
    "    \n",
    "     Y1t[j-1]=stdev1t[j-1]*e5t\n",
    "     Y2t[j-1]=stdev2t[j-1]*e6t\n",
    "     Y3t[j-1]=stdev3t[j-1]*e7t\n",
    "     Y4t[j-1]=stdev4t[j-1]*e8t\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96b34706-3f60-4c7d-b32a-6c31987b0d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    " #validation data\n",
    " for j in range(2,(nv+1)):\n",
    "    \n",
    "     indexv[j-1]=np.random.uniform(-2,2+10**-10,1)\n",
    "     e1v=np.random.uniform(0,1+10**-10,1)\n",
    "     e2v=np.random.uniform(0,1+10**-10,1)\n",
    "     e3v=np.random.uniform(0,1+10**-10,1)\n",
    "     e4v=np.random.uniform(0,1+10**-10,1)\n",
    "     e31v=(0.2*(e1v)**2)+0.8\n",
    "     e32v=(0.2*np.exp(e1v))+0.8\n",
    "     e41v=(0.2*(e2v)**2)+0.8\n",
    "     e42v=(0.2*np.exp(e2v))+0.8\n",
    "     e51v=(0.2*(e3v)**2)+0.8\n",
    "     e52v=(0.2*np.exp(e3v))+0.8\n",
    "     e61v=(0.2*(e4v)**2)+0.8\n",
    "     e62v=(0.2*np.exp(e4v))+0.8\n",
    "    \n",
    "     e5v=np.random.normal(0,1,1)\n",
    "     e6v=np.random.normal(0,1,1)   \n",
    "     e7v=np.random.normal(0,1,1) \n",
    "     e8v=np.random.normal(0,1,1) \n",
    "\n",
    "     coefx1v[j-1,]=[g10(indexv[j-1]).item(),(g11(indexv[j-1])*e31v).item(),(g12(indexv[j-1])*e32v).item(),(g13(indexv[j-1])*e31v).item(),(g14(indexv[j-1])*e32v).item(),g15(indexv[j-1]).item(),g16(indexv[j-1]).item(),g17(indexv[j-1]).item(),g18(indexv[j-1]).item()]\n",
    "     coefx2v[j-1,]=[g20(indexv[j-1]).item(),(g21(indexv[j-1])*e41v).item(),(g22(indexv[j-1])*e42v).item(),(g23(indexv[j-1])*e41v).item(),(g24(indexv[j-1])*e42v).item(),g25(indexv[j-1]).item(),g26(indexv[j-1]).item(),g27(indexv[j-1]).item(),g28(indexv[j-1]).item()]\n",
    "     coefx3v[j-1,]=[g30(indexv[j-1]).item(),(g31(indexv[j-1])*e51v).item(),(g32(indexv[j-1])*e52v).item(),(g33(indexv[j-1])*e51v).item(),(g34(indexv[j-1])*e52v).item(),g35(indexv[j-1]).item(),g36(indexv[j-1]).item(),g37(indexv[j-1]).item(),g38(indexv[j-1]).item()]\n",
    "     coefx4v[j-1,]=[g40(indexv[j-1]).item(),(g41(indexv[j-1])*e61v).item(),(g42(indexv[j-1])*e62v).item(),(g43(indexv[j-1])*e61v).item(),(g44(indexv[j-1])*e62v).item(),g45(indexv[j-1]).item(),g46(indexv[j-1]).item(),g47(indexv[j-1]).item(),g48(indexv[j-1]).item()]\n",
    "    \n",
    "     stdev1v[j-1]=np.dot(coefx1v[j-1,],[1,stdev1v[j-2].item(),stdev2v[j-2].item(),stdev3v[j-2].item(),stdev4v[j-2].item(),np.absolute(Y1v[j-2]).item(),np.absolute(Y2v[j-2]).item(),np.absolute(Y3v[j-2]).item(),np.absolute(Y4v[j-2]).item()])\n",
    "     stdev2v[j-1]=np.dot(coefx2v[j-1,],[1,stdev1v[j-2].item(),stdev2v[j-2].item(),stdev3v[j-2].item(),stdev4v[j-2].item(),np.absolute(Y1v[j-2]).item(),np.absolute(Y2v[j-2]).item(),np.absolute(Y3v[j-2]).item(),np.absolute(Y4v[j-2]).item()])\n",
    "     stdev3v[j-1]=np.dot(coefx3v[j-1,],[1,stdev1v[j-2].item(),stdev2v[j-2].item(),stdev3v[j-2].item(),stdev4v[j-2].item(),np.absolute(Y1v[j-2]).item(),np.absolute(Y2v[j-2]).item(),np.absolute(Y3v[j-2]).item(),np.absolute(Y4v[j-2]).item()])\n",
    "     stdev4v[j-1]=np.dot(coefx4v[j-1,],[1,stdev1v[j-2].item(),stdev2v[j-2].item(),stdev3v[j-2].item(),stdev4v[j-2].item(),np.absolute(Y1v[j-2]).item(),np.absolute(Y2v[j-2]).item(),np.absolute(Y3v[j-2]).item(),np.absolute(Y4v[j-2]).item()])\n",
    "    \n",
    "     Y1v[j-1]=stdev1v[j-1]*e5v\n",
    "     Y2v[j-1]=stdev2v[j-1]*e6v\n",
    "     Y3v[j-1]=stdev3v[j-1]*e7v\n",
    "     Y4v[j-1]=stdev4v[j-1]*e8v\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "615f6ac6-5aae-4e99-80b8-02625b9d2e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    " #testing data\n",
    " Y1=Y1[1:n]\n",
    " Y2=Y2[1:n]\n",
    " Y3=Y3[1:n]\n",
    " Y4=Y4[1:n]\n",
    " stdev1=stdev1[1:n]\n",
    " stdev2=stdev2[1:n]\n",
    " stdev3=stdev3[1:n]\n",
    " stdev4=stdev4[1:n]\n",
    " index=index[1:n]\n",
    " n=np.size(index,0)\n",
    "\n",
    " #training data\n",
    " Y1t=Y1t[1:nt]\n",
    " Y2t=Y2t[1:nt]\n",
    " Y3t=Y3t[1:nt]\n",
    " Y4t=Y4t[1:nt]\n",
    " stdev1t=stdev1t[1:nt]\n",
    " stdev2t=stdev2t[1:nt]\n",
    " stdev3t=stdev3t[1:nt]\n",
    " stdev4t=stdev4t[1:nt]\n",
    " indext=indext[1:nt]\n",
    " nt=np.size(indext,0)\n",
    "\n",
    " #validation data\n",
    " Y1v=Y1v[1:nv]\n",
    " Y2v=Y2v[1:nv]\n",
    " Y3v=Y3v[1:nv]\n",
    " Y4v=Y4v[1:nv]\n",
    " stdev1v=stdev1v[1:nv]\n",
    " stdev2v=stdev2v[1:nv]\n",
    " stdev3v=stdev3v[1:nv]\n",
    " stdev4v=stdev4v[1:nv]\n",
    " indexv=indexv[1:nv]\n",
    " nv=np.size(indexv,0)\n",
    "\n",
    " ymax1=np.max(Y1)\n",
    " ymax2=np.max(Y2)\n",
    " ymin1=np.min(Y1)\n",
    " ymin2=np.min(Y2)\n",
    " ymax3=np.max(Y3)\n",
    " ymax4=np.max(Y4)\n",
    " ymin3=np.min(Y3)\n",
    " ymin4=np.min(Y4)\n",
    "\n",
    " yrange1=np.max(ymax1)-np.min(ymin1)\n",
    " yrange2=np.max(ymax2)-np.min(ymin2)\n",
    " yrange3=np.max(ymax3)-np.min(ymin3)\n",
    " yrange4=np.max(ymax4)-np.min(ymin4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3678b3f8-7025-47da-b513-90c80343d14c",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Preliminary step\n",
    " L=int(np.floor(0.8*(n^(1/8)))\n",
    " preY=np.hstack((Y1,Y2,Y3,Y4))\n",
    " Y=np.hstack((Y1[(L+1):(n-1)],Y2[(L+1):(n-1)],Y3[(L+1):(n-1)],Y4[(L+1):(n-1)]))\n",
    " indexz=index[(L+1):(n-1)]\n",
    " kap=np.size(preY,1)\n",
    " preY11=np.zeros(((n-L-2),(kap*(L+1))))\n",
    " indexzz=np.zeros(((n-L-2),(L+1)))\n",
    "\n",
    " preYt=np.hstack((Y1t,Y2t,Y3t,Y4t))\n",
    " Yt=np.hstack((Y1t[(L+1):(nt-1)],Y2t[(L+1):(nt-1)],Y3t[(L+1):(nt-1)],Y4t[(L+1):(nt-1)]))\n",
    " indexzt=index[(L+1):(nt-1)]\n",
    " kap=np.size(preYt,1)\n",
    " preY11t=np.zeros(((nt-L-2),(kap*(L+1))))\n",
    " indexzzt=np.zeros(((nt-L-2),(L+1)))\n",
    "\n",
    " preYv=np.hstack((Y1v,Y2v,Y3v,Y4v))\n",
    " Yv=np.hstack((Y1v[(L+1):(nv-1)],Y2v[(L+1):(nv-1)],Y3v[(L+1):(nv-1)],Y4v[(L+1):(nv-1)]))\n",
    " indexzv=indexv[(L+1):(nv-1)]\n",
    " kap=np.size(preYv,1)\n",
    " preY11v=np.zeros(((nv-L-2),(kap*(L+1))))\n",
    " indexzzv=np.zeros(((nv-L-2),(L+1)))\n",
    "  \n",
    " for lg in range(L+1):\n",
    "    \n",
    "   preY11[:,(kap*lg):(kap*(lg+1))]=np.absolute(preY[((L+1)-lg-1):(n-1-lg-1),:])\n",
    "   indexzz[:,lg]=index[((L+1)-(lg)):((n-1)-(lg))].reshape(-1)\n",
    "\n",
    "   preY11t[:,(kap*lg):(kap*(lg+1))]=np.absolute(preYt[((L+1)-lg-1):(nt-1-lg-1),:])\n",
    "   indexzzt[:,lg]=indext[((L+1)-(lg)):((nt-1)-(lg))].reshape(-1)\n",
    "\n",
    "   preY11v[:,(kap*lg):(kap*(lg+1))]=np.absolute(preYv[((L+1)-lg-1):(nv-1-lg-1),:])\n",
    "   indexzzv[:,lg]=indexv[((L+1)-(lg)):((nv-1)-(lg))].reshape(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6554ac75-158e-4da7-9478-6f6544d696b3",
   "metadata": {},
   "outputs": [],
   "source": [
    " nm0=np.zeros((L+2,1))\n",
    " for l in range(L+1):\n",
    "   nm0[(l+1)]=nm0[l]+(l+1)+kap\n",
    " nm=nm0.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c53b199f-6052-4a76-bfdc-e232ed01ace7",
   "metadata": {},
   "outputs": [],
   "source": [
    " x_trainin=np.zeros((nt-L-2,nm[L+1][0]))\n",
    " for ll in range(L+1):\n",
    "   x_trainin[:,(nm[ll][0]):nm[(ll+1)][0]]=np.hstack((indexzzt[:,0:(ll+1)],preY11t[:,(kap*ll):(kap*(ll+1))]))\n",
    "\n",
    " x_testin=np.zeros((n-L-2,nm[L+1][0]))\n",
    " for ll in range(L+1):\n",
    "   x_testin[:,(nm[ll][0]):nm[(ll+1)][0]]=np.hstack((indexzz[:,0:(ll+1)],preY11[:,(kap*ll):(kap*(ll+1))]))\n",
    "\n",
    " x_valin=np.zeros((nv-L-2,nm[L+1][0]))\n",
    " for ll in range(L+1):\n",
    "   x_valin[:,(nm[ll][0]):nm[(ll+1)][0]]=np.hstack((indexzzv[:,0:(ll+1)],preY11v[:,(kap*ll):(kap*(ll+1))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "891f58fc-63d4-4b6c-93a8-6b8e225f7390",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Convert data into tensor for DNN\n",
    " ##testing data\n",
    " Y_1=torch.tensor(Y[:,0].reshape(-1,1).astype('float32'))\n",
    " Y_2=torch.tensor(Y[:,1].reshape(-1,1).astype('float32'))\n",
    " Y_3=torch.tensor(Y[:,2].reshape(-1,1).astype('float32'))\n",
    " Y_4=torch.tensor(Y[:,3].reshape(-1,1).astype('float32'))\n",
    " indexz=torch.tensor(indexz.astype('float32'))\n",
    "\n",
    " preY11=torch.tensor(preY11.astype('float32'))\n",
    " indexzz=torch.tensor(indexzz.astype('float32'))\n",
    " #x_test=torch.cat((indexzz,preY11),1) \n",
    " x_test=torch.tensor(x_testin.astype('float32'))\n",
    "\n",
    " ##training data\n",
    " Y_1t=torch.tensor(Yt[:,0].reshape(-1,1).astype('float32'))\n",
    " Y_2t=torch.tensor(Yt[:,1].reshape(-1,1).astype('float32'))\n",
    " Y_3t=torch.tensor(Yt[:,2].reshape(-1,1).astype('float32'))\n",
    " Y_4t=torch.tensor(Yt[:,3].reshape(-1,1).astype('float32'))\n",
    " indexzt=torch.tensor(indexzt.astype('float32'))\n",
    "\n",
    " preY11t=torch.tensor(preY11t.astype('float32'))\n",
    " indexzzt=torch.tensor(indexzzt.astype('float32'))\n",
    " #x_train=torch.cat((indexzzt,preY11t),1) \n",
    " x_train=torch.tensor(x_trainin.astype('float32'))\n",
    "\n",
    " ##validation data\n",
    " Y_1v=torch.tensor(Yv[:,0].reshape(-1,1).astype('float32'))\n",
    " Y_2v=torch.tensor(Yv[:,1].reshape(-1,1).astype('float32'))\n",
    " Y_3v=torch.tensor(Yv[:,2].reshape(-1,1).astype('float32'))\n",
    " Y_4v=torch.tensor(Yv[:,3].reshape(-1,1).astype('float32'))\n",
    " indexzv=torch.tensor(indexzv.astype('float32'))\n",
    "\n",
    " preY11v=torch.tensor(preY11v.astype('float32'))\n",
    " indexzzv=torch.tensor(indexzzv.astype('float32'))\n",
    " x_val=torch.tensor(x_valin.astype('float32'))\n",
    " #x_val=torch.cat((indexzzv,preY11v),1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2aaf87f5-e3e3-439b-a001-81ea5ea604e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "model239\n",
      "验证集最高准确率： \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_6536\\1503340234.py:59: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  Netnew1=torch.load(r'E:/learning_python/weights/catdogclassifi_0.15_4000_1-%s.pth' % (min_index1 + 1))\n"
     ]
    }
   ],
   "source": [
    " # training Quantile Regression\n",
    " #dim_nonpar=np.size(x_trainin,1)\n",
    " dim_nonpar=np.size(x_train,1)\n",
    "\n",
    " # hyperparameters\n",
    " nodes = [2,128]     # number of network layers and nodes per layer\n",
    " lr = 0.001          #learning rate\n",
    " epochs = 500\n",
    " verbose = False\n",
    " sparseRatio = 0.5   #proportion of 0 elements in weight matrix\n",
    "\n",
    " ## loss function\n",
    " def check_loss(y_pred: Tensor, target: Tensor, tau: float) -> Tensor:\n",
    "    errors = target-y_pred \n",
    "    u = torch.max(tau*errors,(tau-1)*errors)\n",
    "    return u.mean()\n",
    "\n",
    " EPOCH = epochs\n",
    "\n",
    " reslist1 = []\n",
    " Train_Loss_list1 = []\n",
    " Valid_Loss_list1 = []\n",
    "\n",
    " Net1=dqNetSparse(dim_nonpar,nodes,sparseRatio)\n",
    " optimizer1=torch.optim.Adam(Net1.parameters(),lr=lr)\n",
    "\n",
    " #training step\n",
    " model_path=\"E:/learning_python/weights\"   #path of saving model file in each epoch\n",
    "\n",
    " for epoch in range(1, EPOCH + 1):\n",
    "\n",
    "    prediction1t=Net1(x_train) \n",
    "    train_loss1 = check_loss(prediction1t,Y_1t,tau) \n",
    "    optimizer1.zero_grad() \n",
    "    train_loss1.backward() \n",
    "    optimizer1.step() \n",
    "     \n",
    "    Train_Loss_list1.append(train_loss1)\n",
    "    torch.save(Net1, os.path.join(model_path, 'catdogclassifi_0.15_4000_1-%s.pth' % epoch))  #saving model file in each epoch\n",
    "     \n",
    "    # validation\n",
    "    y_fval1=Net1(x_val)\n",
    "    test_loss1= check_loss(y_fval1,Y_1v,tau)\n",
    "    Valid_Loss_list1.append(test_loss1)\n",
    "    reslist1.append(test_loss1)\n",
    "    print(epoch)    \n",
    "\n",
    " min_num1 = min(reslist1)\n",
    " min_index1 = reslist1.index(min_num1)\n",
    " #min_num1 = min(Train_Loss_list1)\n",
    " #min_index1 = Train_Loss_list1.index(min_num1)\n",
    " print('model%s' % (min_index1 + 1))              #print the number of order of the best model\n",
    "\n",
    " Netnew1=torch.load(r'E:/learning_python/weights/catdogclassifi_0.15_4000_1-%s.pth' % (min_index1 + 1))  #save the best model\n",
    " sigmatile1=Netnew1(x_test).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94a429ef-d0ec-45d5-a3f2-8d7d5a90efab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "model284\n",
      "验证集最高准确率： \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_6536\\3915685258.py:40: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  Netnew2=torch.load(r'E:/learning_python/weights/catdogclassifi_0.15_4000_2-%s.pth' % (min_index2 + 1))\n"
     ]
    }
   ],
   "source": [
    " ##Y_2\n",
    "\n",
    " reslist2 = []\n",
    " Train_Loss_list2 = []\n",
    " Valid_Loss_list2 = []\n",
    "\n",
    " Net2=dqNetSparse(dim_nonpar,nodes,sparseRatio)\n",
    " optimizer2=torch.optim.Adam(Net2.parameters(),lr=lr)\n",
    "\n",
    " #training step\n",
    " model_path=\"E:/learning_python/weights\"\n",
    " \n",
    " for epoch in range(1, EPOCH + 1):\n",
    "\n",
    "    prediction2t=Net2(x_train) \n",
    "    train_loss2 = check_loss(prediction2t,Y_2t,tau) \n",
    "    optimizer2.zero_grad() \n",
    "    train_loss2.backward() \n",
    "    optimizer2.step() \n",
    "     \n",
    "    Train_Loss_list2.append(train_loss2)\n",
    "    torch.save(Net2, os.path.join(model_path, 'catdogclassifi_0.15_4000_2-%s.pth' % epoch))\n",
    "     \n",
    "    y_fval2=Net2(x_val)\n",
    "    test_loss2= check_loss(y_fval2,Y_2v,tau)\n",
    "    Valid_Loss_list2.append(test_loss2)\n",
    "    reslist2.append(test_loss2)\n",
    "    print(epoch)\n",
    "     \n",
    " min_num2 = min(reslist2)\n",
    " min_index2 = reslist2.index(min_num2)\n",
    " #min_num2 = min(Train_Loss_list2)\n",
    " #min_index2 = Train_Loss_list2.index(min_num2)\n",
    " print('model%s' % (min_index2 + 1))\n",
    "\n",
    " Netnew2=torch.load(r'E:/learning_python/weights/catdogclassifi_0.15_4000_2-%s.pth' % (min_index2 + 1))\n",
    " sigmatile2=Netnew2(x_test).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5b90564-98a4-47f4-afd2-ecdee135c6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "model139\n",
      "验证集最高准确率： \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_6536\\3204006099.py:40: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  Netnew3=torch.load(r'E:/learning_python/weights/catdogclassifi_0.15_4000_3-%s.pth' % (min_index3 + 1))\n"
     ]
    }
   ],
   "source": [
    " ##Y_3\n",
    " reslist3 = []\n",
    " Train_Loss_list3 = []\n",
    " Valid_Loss_list3 = []\n",
    "\n",
    " Net3=dqNetSparse(dim_nonpar,nodes,sparseRatio)\n",
    " optimizer3=torch.optim.Adam(Net3.parameters(),lr=lr)\n",
    "\n",
    " # training step\n",
    " model_path=\"E:/learning_python/weights\"\n",
    "\n",
    " for epoch in range(1, EPOCH + 1):\n",
    "\n",
    "    prediction3t=Net3(x_train) \n",
    "    train_loss3 = check_loss(prediction3t,Y_3t,tau) \n",
    "    optimizer3.zero_grad() \n",
    "    train_loss3.backward() \n",
    "    optimizer3.step() \n",
    "\n",
    "    Train_Loss_list3.append(train_loss3)\n",
    "    torch.save(Net3, os.path.join(model_path, 'catdogclassifi_0.15_4000_3-%s.pth' % epoch))\n",
    "     \n",
    "    y_fval3=Net3(x_val)\n",
    "    test_loss3= check_loss(y_fval3,Y_3v,tau)\n",
    "    Valid_Loss_list3.append(test_loss3)\n",
    "    reslist3.append(test_loss3)\n",
    "     \n",
    "    print(epoch)\n",
    "     \n",
    " min_num3 = min(reslist3)\n",
    " min_index3 = reslist3.index(min_num3)\n",
    " #min_num3 = min(Train_Loss_list3)\n",
    " #min_index3 = Train_Loss_list3.index(min_num3)\n",
    " print('model%s' % (min_index3 + 1))\n",
    "\n",
    " Netnew3=torch.load(r'E:/learning_python/weights/catdogclassifi_0.15_4000_3-%s.pth' % (min_index3 + 1))\n",
    " sigmatile3=Netnew3(x_test).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a543aca-e6a4-45b3-8275-94c36d9a085a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "model187\n",
      "验证集最高准确率： \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_6536\\2284064140.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  Netnew4=torch.load(r'E:/learning_python/weights/catdogclassifi_0.15_4000_4-%s.pth' % (min_index4 + 1))\n"
     ]
    }
   ],
   "source": [
    " ##Y_4\n",
    " reslist4 = []\n",
    " Train_Loss_list4 = []\n",
    " Valid_Loss_list4 = []\n",
    "\n",
    " Net4=dqNetSparse(dim_nonpar,nodes,sparseRatio)\n",
    " optimizer4=torch.optim.Adam(Net4.parameters(),lr=lr)\n",
    "\n",
    " # training step\n",
    " model_path=\"E:/learning_python/weights\"\n",
    "\n",
    " for epoch in range(1, EPOCH + 1):\n",
    "\n",
    "    prediction4t=Net4(x_train) \n",
    "    train_loss4 = check_loss(prediction4t,Y_4t,tau) \n",
    "    optimizer4.zero_grad() \n",
    "    train_loss4.backward() \n",
    "    optimizer4.step()     \n",
    "\n",
    "    Train_Loss_list4.append(train_loss4)\n",
    "    torch.save(Net4, os.path.join(model_path, 'catdogclassifi_0.15_4000_4-%s.pth' % epoch))\n",
    "     \n",
    "    y_fval4=Net4(x_val)\n",
    "    test_loss4= check_loss(y_fval4,Y_4v,tau)\n",
    "    Valid_Loss_list4.append(test_loss4)\n",
    "    reslist4.append(test_loss4)\n",
    "    print(epoch)\n",
    "     \n",
    " min_num4 = min(reslist4)\n",
    " min_index4 = reslist4.index(min_num4)\n",
    " #min_num4 = min(Train_Loss_list4)\n",
    " #min_index4 = Train_Loss_list4.index(min_num4)\n",
    " print('model%s' % (min_index4 + 1))\n",
    "\n",
    " Netnew4=torch.load(r'E:/learning_python/weights/catdogclassifi_0.15_4000_4-%s.pth' % (min_index4 + 1))\n",
    " sigmatile4=Netnew4(x_test).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99b4dca4-e23c-4da0-ad8d-bda73020f4f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "239"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_index1 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e02e0eea-985b-479a-9f4a-928fdf46654a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "284"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_index2 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cdfec3d0-efa7-499d-8e19-cf088c8d0a9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_index3 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa3995cb-fbef-4959-95db-ab720e1e5a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_index4 + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
